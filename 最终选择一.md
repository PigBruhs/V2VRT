## ASR（云端）sherpa‑onnx

---

模型背景与能力：基于 k2‑fsa 的推理栈；主流后端为 ONNX Runtime；提供 RNN‑T；Conformer；Zipformer 多语与中文强化模型；支持流式与离线；可选 CTC 模型。

技术细节：16 kHz 单声道；chunk‑based 流式解码；可用 ORT CPU EP；动态或静态 INT8 量化；小 beam 设置与短窗延迟优化；可配合 Silero VAD；时间戳与简单标点后处理。

预估性能（i5‑13500H）：Zipformer 小中型多语模型；RTF≈0.25–0.6（单路）；端到端流式延迟≈120–250 ms；常驻内存≈0.6–1.2 GB（含模型＋缓冲）；并发实时路数≈4–10（取决于量化与线程亲和）；离线吞吐 2–4× 实时。

## ASR（手机端）sherpa‑ncnn

模型背景与能力：面向移动端的 NCNN 推理；支持 Zipformer；RNN‑T；多语模型；主打低延迟流式。
技术细节：NCNN＋Vulkan 加速；FP16／INT8；20–40 ms 帧；小 beam；短 chunk；可本地 VAD；轻量标点模型或规则断句。
预估性能（骁龙 8 Gen 1）：RTF≈0.25–0.6（流式；16 kHz）；首包延迟≈120–250 ms；常驻内存≈120–400 MB；在嘈杂与重口音下准确度略低于 Whisper‑small；功耗中等。

## NLP（云端）M2M100‑418M（CTranslate2 INT8）
模型背景与能力：Meta 多语直译模型；418M 参数；支持百余语种任意互译；长句结构与一致性优于多数单语对模型。
技术细节：Transformer 编码器‑解码器；SentencePiece；CT2 INT8 推理；多线程；支持 beam；长度惩罚；分句并发；占位符保护。
预估性能（i5‑13500H）：内存占用≈1.8–3.0 GB；吞吐≈50–130 token/s（8–12 线程；INT8）；短句〈25 token 延迟≈200–600 ms；长句线性增长；并发 2–4 路近实时。

## NLP（手机端）Marian NMT（CTranslate2；OPUS‑MT 分语对）
模型背景与能力：OPUS‑MT 覆盖常见语对；每个方向独立模型；通用文本稳健；轻量、易部署。
技术细节：Transformer；SentencePiece；CT2 INT8；ARM NEON；可贪心或小 beam；句级切分并发。
预估性能（骁龙 8 Gen 1）：模型体积≈80–300 MB／语对；内存≈200–600 MB；吞吐≈80–180 token/s；短句〈20 token 延迟≈100–250 ms；冷启动加载≈200–800 ms。

## TTS（云端）Coqui TTS（XTTS v2 多语）
模型背景与能力：多语跨语种；支持少样本音色克隆；自然度高；22.05–24 kHz 常见；支持情感与风格控制（取决于发行）。
技术细节：自回归声学模型＋神经声码器（HiFi‑GAN／BigVGAN 系）；可流式分块；文本正则化；SSML 近似能力由前后处理实现。
预估性能（i5‑13500H；CPU）：RTF≈0.3–0.9（22 kHz；优化后）；首音延迟≈400–1000 ms；内存≈1.5–3.0 GB；实时并发 1–2 路；离线批量可提升吞吐。注：无 CUDA 时延迟较高，建议缓存与分句并发。
## TTS（手机端）Kitten TTS

模型背景与能力：未有统一的开源标准发行版名为“Kitten TTS”。此处按“轻量移动端 TTS”范式描述；通常基于精简 VITS／FastPitch＋HiFi‑GAN 小体积声码器，面向端侧低延迟合成。
技术细节：NCNN／ONNX Runtime Mobile；FP16／INT8；22.05 kHz 为主；支持分句分块与缓存；必要时简化文本正则。
预估性能（骁龙 8 Gen 1）：RTF≈0.5–1.2（22 kHz；看模型规模与量化）；首音延迟≈150–300 ms；内存≈150–400 MB；音色与语种依具体模型包而定；跨语种自然度通常低于 XTTS v2，但实时性更佳。
## 工程与部署要点（两端共通）
音频与流控：统一 16 kHz 单声道；ASR 采用短 chunk；VAD 裁剪静音；TTS 端分句并发＋拼接淡入出。
量化与线程：ORT／CT2 的 INT8 优先；合理设置 OMP 线程、亲和与批量；移动端启用 Vulkan／NEON。
文本管线：句级切分；占位符／HTML 保护；数字与单位正则；ASR 标点与断句轻量后处理。
观测：记录 RTF；QPS；首包延迟；内存与热；根据目标延迟调整 beam；chunk；并发度。